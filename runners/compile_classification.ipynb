{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20661f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dd93fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing pickle files\n",
    "directory = Path(\"../results/classification/quantitative\")\n",
    "\n",
    "# Optionally filter for specific substrings\n",
    "pkl_files = [f for f in directory.iterdir() if f.suffix == \".pkl\"]\n",
    "\n",
    "# Efficient loader\n",
    "def load_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            if isinstance(data, dict):\n",
    "                return file_path.name, data\n",
    "    except (EOFError, pickle.UnpicklingError) as e:\n",
    "        print(f\"Warning: Failed to load {file_path.name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error with {file_path.name}: {e}\")\n",
    "    return None\n",
    "\n",
    "# Load files using multithreading (I/O bound)\n",
    "all_data = {}\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(load_file, f) for f in pkl_files]\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            filename, data = result\n",
    "            all_data[filename] = data\n",
    "\n",
    "files = list(all_data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7131e3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10011, 15)\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "for file, dictionary in all_data.items():\n",
    "    records.append(dictionary)\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30b43dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df.melt(\n",
    "        id_vars=['name', 'random_state', 'prox_method', 'conformity_k'],\n",
    "        value_vars=[\n",
    "                'ice_auc', 'diff_proba_auc', 'conformity_auc',\n",
    "                'ice_auc_test', 'diff_proba_auc_test', 'conformity_auc_test',\n",
    "                'tree_conformity_auc', 'tree_conformity_auc_test'\n",
    "        ],\n",
    "        var_name='metric',\n",
    "        value_name='auc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eed2c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long['Method'] = df_long['metric']\n",
    "\n",
    "df_long.loc[df_long['metric'] == 'ice_auc', 'Method'] = 'RF-ICE (EMR)'\n",
    "df_long.loc[(df_long['metric'] == 'conformity_auc') & (df_long['prox_method'] == 'original'), 'Method'] = 'Conformity'\n",
    "df_long.loc[(df_long['metric'] == 'conformity_auc') & (df_long['prox_method'] == 'rfgap'), 'Method'] = 'RF-ICE Conformity'\n",
    "df_long.loc[df_long['metric'] == 'diff_proba_auc', 'Method'] = 'Proba. Diff.'\n",
    "df_long.loc[df_long['metric'] == 'tree_conformity_auc', 'Method'] = 'Tree Conformity'\n",
    "\n",
    "\n",
    "methods = ['RF-ICE (EMR)', 'Conformity', 'RF-ICE Conformity', 'Proba. Diff.', 'Tree Conformity']\n",
    "df_long = df_long[df_long['Method'].isin(methods)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d42a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df_long.groupby(['prox_method', 'conformity_k', 'metric'])['auc'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "df_group.loc[\n",
    "    df_group['metric'].isin([\n",
    "        'diff_proba_auc', 'diff_proba_auc_test',\n",
    "        'tree_conformity_auc', 'tree_conformity_auc_test'\n",
    "    ]),\n",
    "    'prox_method'\n",
    "] = 'NA'\n",
    "\n",
    "\n",
    "# Subset for the compared methods\n",
    "\n",
    "\n",
    "df_group['Method'] = df_group['metric']\n",
    "\n",
    "df_group.loc[df_group['metric'] == 'ice_auc', 'Method'] = 'RF-ICE (EMR)'\n",
    "df_group.loc[(df_group['metric'] == 'conformity_auc') & (df_group['prox_method'] == 'original'), 'Method'] = 'Conformity'\n",
    "df_group.loc[(df_group['metric'] == 'conformity_auc') & (df_group['prox_method'] == 'rfgap'), 'Method'] = 'RF-ICE Conformity'\n",
    "df_group.loc[df_group['metric'] == 'diff_proba_auc', 'Method'] = 'Proba. Diff.'\n",
    "df_group.loc[df_group['metric'] == 'tree_conformity_auc', 'Method'] = 'Tree Conformity'\n",
    "\n",
    "# Carefull with this one!\n",
    "methods = ['RF-ICE (EMR)', 'Conformity', 'RF-ICE Conformity', 'Proba. Diff.', 'Tree Conformity']\n",
    "df_group = df_group[df_group['Method'].isin(methods)]\n",
    "# df_group.drop(columns=['prox_method', 'conformity_k', 'metric'], inplace=True)\n",
    "\n",
    "df_group.reset_index(drop = True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0db0914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_group = df_group[df_group['conformity_k'] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "890cf703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "Method & AUC \\\\\n",
      "\\midrule\n",
      "RF-ICE Conformity & 0.965 ± 0.068 \\\\\n",
      "Conformity & 0.964 ± 0.069 \\\\\n",
      "RF-ICE (EMR) & 0.932 ± 0.099 \\\\\n",
      "Proba. Diff. & 0.929 ± 0.118 \\\\\n",
      "Tree Conformity & 0.730 ± 0.196 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_latex = df_group.groupby('Method')[['mean', 'std']].mean().sort_values('mean', ascending=False).reset_index()\n",
    "df_latex['AUC'] = df_latex.apply(lambda row: f\"{row['mean']:.3f} ± {row['std']:.3f}\", axis=1)\n",
    "latex_table = df_latex[['Method', 'AUC']].to_latex(index=False)\n",
    "print(latex_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rf-uncertainty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
